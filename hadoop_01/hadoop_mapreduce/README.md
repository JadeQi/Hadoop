## 说明
partition包: 需求: 按照数据第6个字段，将原有存在与一个文件中的数据，拆分为2个文件[集群运行]

```
1	0	1	2017-07-31 23:10:12	837255	6	4+1+1=6	小,双
2	0	1	2017-07-31 23:15:03	837256	14	4+7+3=14	大,双
3	0	1	2017-07-31 23:20:12	837257	17	6+9+2=17	大,单
4	0	1	2017-07-31 23:25:12	837258	22	5+8+9=22	大,双
5	0	1	2017-07-31 23:30:18	837259	1	1+0+0=1	小,单
6	0	2	2017-07-31 23:17:22	2170779	4	2+0+2=4	小,双
7	0	2	2017-07-31 23:20:49	2170780	12	1+2+9=12	小,双
```

```properties
# 集群运行: 
# 上传resource--partition下的jar包到服务器中
	hadoop jar com.JadePenG.partition.MyPartitionJobMain [输入路径]  [输出路径]

com.JadePenG.pcom.JadePenG.partition	hdfs dfs -mkdir -p [文件夹输入路径]
	hdfs dfs -put partition.csv [文件夹com.JadePenG.partition



sort包: 排序  第一列按照字典顺序进行排列，第一列相同的时候，第二列按照升序进行排列

```
a	1
a	9
b	3
a	7
b	8
b	10
a	9
```

